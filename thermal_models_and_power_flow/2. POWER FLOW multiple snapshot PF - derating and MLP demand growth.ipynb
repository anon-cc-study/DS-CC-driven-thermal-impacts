{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43182ae-1211-42d2-8cfd-63a189b3b327",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Solve power flow with MLP load predictions and weather dependent capacity ratings and heat losses\n",
    "\n",
    "This notebook does the following:\n",
    "\n",
    "1. Define path to Master file corresponding to TGW year and scenario\n",
    "2. Solve Power flow\n",
    "3. Save lines and Xfer data at each timestep (current, voltage, power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51553484-4168-467b-b3d4-90f1251ebd85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903a2e7-1937-48f8-90be-185d247709a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f368cdfc-c6a7-40f7-bc23-b72ad66b8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np \n",
    "import pandas as pd # to create data frames\n",
    "import pyarrow as pa\n",
    "import xarray as xr\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil #To enable duplicating files\n",
    "from opendssdirect import dss\n",
    "from src import physics_ops\n",
    "from src import file_ops\n",
    "from src import opendss_ops\n",
    "from src import TGW_ops\n",
    "from src import input_ops\n",
    "from src import df_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0d95a-7874-4057-a58b-ae3c1fd85355",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load config file with scenarios and parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d5b384-f9c6-4ff0-86cf-b47f3425f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name = 'opendss_config1'; config_path = f\"main_folder/config/{config_file_name}.yaml\"; config = input_ops.load_config(config_path)\n",
    "\n",
    "enable_save = 1  # 1 enable | 0 disable\n",
    "\n",
    "TGW_years_scenarios = config['TGW_years_scenarios']\n",
    "\n",
    "demand_mode = config['demand_mode']\n",
    "    \n",
    "aggregation_level = config['aggregation_level']\n",
    "\n",
    "CITY_REGIONS_TO_RUN = config['CITY_REGIONS_TO_RUN']\n",
    "\n",
    "input_data_dict_name = config['input_data_dict_name']\n",
    "aggregation_level = config['aggregation_level']\n",
    "smart_ds_year = config['smart_ds_years'][0]\n",
    "building_types = config[\"building_types\"]\n",
    "\n",
    "input_data_training_path = config['input_data_training_path']\n",
    "CITY_REGIONS_TO_RUN = config['CITY_REGIONS_TO_RUN']\n",
    "start_month = config['start_month']\n",
    "end_month = config['end_month']\n",
    "\n",
    "## Initialize parameters for saving paths\n",
    "Y_column = config['Y_column']\n",
    "input_data_prediction_path = config['input_data_prediction_path']\n",
    "output_path_prediction_str = config['output_data_prediction_path']\n",
    "output_pf_path = config['output_pf_path']\n",
    "\n",
    "smart_ds_year = config['smart_ds_years'][0]\n",
    "smart_ds_load_path = config['smart_ds_load_path'] + f\"/{smart_ds_year}\" # path to procesed smart-ds resstock data \n",
    "   \n",
    "solution_mode = config['solution_mode']\n",
    "\n",
    "## Define variables to create list of mdh to run\n",
    "start_month_mdh = config['start_month_mdh'] \n",
    "end_month_mdh = config['end_month_mdh']\n",
    "top_percent_mdh = config['top_percent_mdh']\n",
    "\n",
    "## Load dictionary, sort by total city aggregated buildings demand, extract mdh of top % load hours\n",
    "## load demand data \n",
    "regional_demand_weather_ampacity_path = smart_ds_load_path + f\"/all_cities/aggregated_demand\"\n",
    "regional_demand_weather_ampacity_all_cities = joblib.load(os.path.join(regional_demand_weather_ampacity_path, \"regional_demand_weather_ampacity_all_cities\"))\n",
    "## Sort your dictionary by aggregated total demand  \n",
    "regional_demand_weather_ampacity_all_cities_sorted = df_ops.sort_nested_dict_dfs(regional_demand_weather_ampacity_all_cities, \"aggregated_predicted_buildings_total_kw\", ascending=False)\n",
    "top_n_hours = int(np.ceil(8760*top_percent_mdh/100)) # calculate top city demand hours to run (top_percent_mdh% of hours of the year)\n",
    "## Define start and end load hours to run\n",
    "start_row_percent = config['start_row_percent']\n",
    "start_row_idx = int(np.ceil(8760*start_row_percent/100)) # index from which to start loop of load hours\n",
    "# start_row_idx = 0 # index from which to start loop of load hours\n",
    "end_row_idx = top_n_hours \n",
    "\n",
    "print(f\"enable_save:{enable_save} \\nsolution_mode: {solution_mode} \\nTGW_years_scenarios:{TGW_years_scenarios} \\nCITY_REGIONS_TO_RUN: {CITY_REGIONS_TO_RUN}  \\n demand mode: {demand_mode}\")\n",
    "\n",
    "print(f\"\\n\\ntop_percent_mdh: {top_percent_mdh}%, top_n_hours: {top_n_hours}, start_row_idx:{start_row_idx} ({start_row_percent}%), end_row_idx:{end_row_idx} ({top_percent_mdh}%) \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403964f-e648-46d0-be7d-69e754eaf70a",
   "metadata": {},
   "source": [
    "## Run power flow \n",
    "Note: should take about 40min for all scenarios and 3 TGW year-scenario combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9427a8-bf12-46e8-af73-b1a8a4c26f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Auxilary parameter \n",
    "pf_converged = 0 # defult value 0,  0 did not converge | 1 converged\n",
    "\n",
    "master_file_option = 'TGW' # Options: TGW | default of smart-ds\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for TGW_weather_year, TGW_scenarios in TGW_years_scenarios.items():\n",
    "    for TGW_scenario in TGW_scenarios:\n",
    "        print(f\"--- Starting scenario: {TGW_weather_year} {TGW_scenario} ---\\n\")\n",
    "        year = TGW_weather_year; \n",
    "        # --- Iterate over all selected regions --- \n",
    "        for city, regions in CITY_REGIONS_TO_RUN.items():\n",
    "            \n",
    "            ## create list of mdh for top % hours\n",
    "            df_city = regional_demand_weather_ampacity_all_cities_sorted[(TGW_weather_year, TGW_scenario)][city]   # load regional demand data to later create list of mdh for top % hours  \n",
    "            list_of_mdh = df_ops.get_top_n_mdh(df_city, top_n_hours, start_month_mdh, end_month_mdh)\n",
    "\n",
    "            for region in regions:\n",
    "                print(f\"--- Starting scenario: {city} {region} ---\\n\")\n",
    "                # --- Iterate over all selected month-day-hour (mdh) --- \n",
    "                for row_i in range(start_row_idx, end_row_idx):\n",
    "                    mdh = list_of_mdh[row_i]; m,d,h = mdh\n",
    "                    print(f\"--- Starting Index: {row_i}, mdh: {mdh} ---\\n\")\n",
    "\n",
    "                    # --- Initialize region's paths ---\n",
    "                    # Create path to regional master file \n",
    "                    if solution_mode == 'snapshot':\n",
    "                        region_path = f\"main_folder/SMART-DS/v1.0/{smart_ds_year}/{city}/{region}/scenarios/base_timeseries/opendss_no_loadshapes\"\n",
    "                    else:\n",
    "                        region_path = f\"main_folder/SMART-DS/v1.0/{smart_ds_year}/{city}/{region}/scenarios/base_timeseries/opendss\"  \n",
    "\n",
    "                    # --- Redirect opendss to new master file  ---\n",
    "                    dss.Basic.ClearAll() \n",
    "\n",
    "                    if master_file_option == 'TGW':\n",
    "                        # --- Redirect opendss to TGW scenario master file  ---\n",
    "                        new_master_dir = os.path.join(region_path, \"predicted_master_files\", TGW_scenario, TGW_weather_year)\n",
    "                        dss.Command(f'Redirect \"{new_master_dir}/Master_{TGW_scenario}_{TGW_weather_year}_{m}_{d}_{h}.dss\"') # Direct opendss engine to master file \n",
    "                    else:\n",
    "                        # --- Redirect opendss to default master file  ---\n",
    "                        dss.Command(f'Redirect \"{region_path}/Master.dss\"') # Direct opendss engine to master file \n",
    "\n",
    "                    # --- Solve power flow ---\n",
    "                    pf_start_time = time.time()\n",
    "                    dss.Solution.Solve()  # Solve the circuit\n",
    "                    if dss.Solution.Converged():\n",
    "                        print(f\"---Power flow solution converged successfully after {dss.Solution.Iterations()} iterations---\\n\")\n",
    "                        pf_converged = 1\n",
    "                    else:\n",
    "                        print(\"---Power flow solution did not converge!---\\n\")\n",
    "                        pf_converged = 0\n",
    "                    pf_end_time = time.time(); print(\"PF solve runtime:\", (pf_end_time - pf_start_time) / 60, \"minutes\")\n",
    "\n",
    "                    # --- Extract line and transformers data (physical properties, loading, voltage etc.) ---\n",
    "                    dict_bus_coord = opendss_ops.create_dict_bus_coord(region_path)  # Create a dictionary of bus names and coordinates from Buscoords.dss\n",
    "                    line_df = opendss_ops.extract_line_information(dict_bus_coord, year,m,d,h,row_i) # Extract line data\n",
    "                    transformer_df = opendss_ops.extract_transformer_information(dict_bus_coord, year,m,d,h,row_i) # Extract transformers data\n",
    "\n",
    "                    # Add current year line and xfer data to multi-year data frame\n",
    "                    if row_i == start_row_idx:\n",
    "                        all_line_df = line_df\n",
    "                        all_transformer_df = transformer_df\n",
    "                    else:\n",
    "                        # concat current df to a multi-year data frame\n",
    "                        all_line_df = pd.concat([all_line_df, line_df], ignore_index=True)\n",
    "                        all_transformer_df = pd.concat([all_transformer_df, transformer_df], ignore_index=True) \n",
    "\n",
    "                # --- Save results per region---     \n",
    "                if master_file_option == 'TGW':\n",
    "                    lines_file_name = f\"lines_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "                    transformers_file_name = f\"transformers_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "                    metadata_file_name = f\"metadata_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "                else:\n",
    "                    lines_file_name = f\"lines_regional_peak_default\"\n",
    "                    transformers_file_name = f\"transformers_regional_peak_default\"\n",
    "                    metadata_file_name = f\"metadata_regional_peak_default\"\n",
    "                    \n",
    "                # Initialize dictionaries\n",
    "                lines_dict = {}\n",
    "                transformers_dict = {}\n",
    "                # Initialize inner dictionary per TGW scenario\n",
    "                lines_dict[(TGW_weather_year,TGW_scenario)] = {}\n",
    "                transformers_dict[(TGW_weather_year,TGW_scenario)] = {}\n",
    "                # Add data frames to 2 level key (smart-ds) of dictionaries\n",
    "                lines_dict[(TGW_weather_year,TGW_scenario)][(smart_ds_year, city, region)] = all_line_df\n",
    "                transformers_dict[(TGW_weather_year,TGW_scenario)][(smart_ds_year, city, region)] = all_transformer_df\n",
    "                \n",
    "                if enable_save == 1:\n",
    "                    # Save dictionaries as joblib files\n",
    "                    if master_file_option == 'TGW':\n",
    "                        predictions_dir = os.path.join(output_pf_path, f\"{city}/{region}/{TGW_scenario}/{TGW_weather_year}/\")\n",
    "                    else:\n",
    "                        predictions_dir = os.path.join(output_pf_path, f\"{city}/{region}/smart_ds_default/{smart_ds_year}\")\n",
    "\n",
    "                    os.makedirs(predictions_dir, exist_ok=True) # Create directories if they don't exist\n",
    "                    \n",
    "                    if pf_converged == 1: \n",
    "                        joblib.dump(lines_dict, os.path.join(predictions_dir, f\"{lines_file_name}.joblib\"))\n",
    "                        joblib.dump(transformers_dict, os.path.join(predictions_dir, f\"{transformers_file_name}.joblib\"))\n",
    "                    else:\n",
    "                        joblib.dump(lines_dict, os.path.join(predictions_dir, f\"{lines_file_name}_did_not_converge.joblib\"))\n",
    "                        joblib.dump(transformers_dict, os.path.join(predictions_dir, f\"{transformers_file_name}_did_not_converge.joblib\"))\n",
    "\n",
    "                    # Define metadata #### !!! Add time array and temp array\n",
    "                    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                    metadata = {\n",
    "                        \"changes\": \"demand_only\",\n",
    "                        \"solution_mode\": solution_mode,\n",
    "                        \"smart_ds_year\": smart_ds_year,\n",
    "                        \"timestamp\": timestamp,\n",
    "                    }\n",
    "                    # Save metadata to a JSON file\n",
    "                    metadata_file = f\"{predictions_dir}{metadata_file_name}.json\"\n",
    "                    with open(metadata_file, 'w') as f:\n",
    "                        json.dump(metadata, f)\n",
    "                    print(f\"---- Results for scenario {city} {region} saved succesfuly in {predictions_dir} ----\\n\")\n",
    "    \n",
    "end_time = time.time(); print(\"Total runtime:\", (end_time - start_time) / 60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb9d1fe-9e44-441e-ae55-a41a643815bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Print bus voltages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be1d1fc-3cd0-47f5-9bb3-f4f7ced7340d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buses = dss.Circuit.AllBusNames()\n",
    "for bus in buses:\n",
    "    dss.Circuit.SetActiveBus(bus)\n",
    "    voltages = dss.Bus.puVmagAngle()\n",
    "    voltages_pu = voltages[::2]\n",
    "    for v in voltages_pu:\n",
    "        if v < 0.9 or v > 1.1:\n",
    "            print(f\"Voltage warning at {bus}: {v:.3f} pu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f325d9c-df34-46ee-8b82-18d070d2198d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Print circuit loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d675d781-937d-4580-8fa9-570cb18a9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total losses\n",
    "losses = dss.Circuit.Losses()\n",
    "total_loss_kw = losses[0] / 1000  # Convert watts to kW          \n",
    "# Get total circuit power \n",
    "total_circuit_power = dss.Circuit.TotalPower() #  sum of all the powers in the first terminal of each source (Vsource and Isource)\n",
    "total_circuit_power_kw = - total_circuit_power[0]  # Real power in kW          \n",
    "# Total load\n",
    "total_circuit_Loads = total_circuit_power_kw -total_loss_kw\n",
    "\n",
    "print(f'Total circuit load: {total_circuit_Loads} kw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8e776-d3df-4ed1-841f-90ba7ffe6ac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Print line and transformer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de65efb5-ec5c-46b1-ab38-f94973c589c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_loading = all_line_df.nlargest(10, 'Loading [%]')\n",
    "display(top_10_loading)\n",
    "top_10_loading = all_transformer_df.nlargest(10, 'Loading [%]')\n",
    "display(top_10_loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456e58f-ad68-4b37-a9b5-9b15c5208577",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load saved PF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e185f068-557f-468a-8b64-75bcf4233f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save results ---     \n",
    "lines_file_name = f\"lines_regional_peak\"\n",
    "transformers_file_name = f\"transformers_regional_peak\"\n",
    "metadata_file_name = f\"metadata_regional_peak\"\n",
    "\n",
    "city = 'GSO'\n",
    "region = 'rural'\n",
    "\n",
    "TGW_weather_year = '2018'\n",
    "TGW_scenario = 'historical'\n",
    "predictions_dir = os.path.join(output_pf_path, f\"{city}/{region}/{TGW_scenario}/{TGW_weather_year}/\")\n",
    "lines_dict_1 = joblib.load(os.path.join(predictions_dir, f\"{lines_file_name}.joblib\"))\n",
    "transformers_dict_1 = joblib.load(os.path.join(predictions_dir, f\"{transformers_file_name}.joblib\"))\n",
    "\n",
    "TGW_weather_year = '2058'\n",
    "TGW_scenario = 'rcp45hotter'\n",
    "predictions_dir = os.path.join(output_pf_path, f\"{city}/{region}/{TGW_scenario}/{TGW_weather_year}/\")\n",
    "lines_dict_2 = joblib.load(os.path.join(predictions_dir, f\"{lines_file_name}.joblib\"))\n",
    "transformers_dict_2 = joblib.load(os.path.join(predictions_dir, f\"{transformers_file_name}.joblib\"))\n",
    "\n",
    "lines_dict = lines_dict_1\n",
    "transformers_dict = transformers_dict_1\n",
    "lines_dict.update(lines_dict_2)\n",
    "transformers_dict.update(transformers_dict_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendss_env2",
   "language": "python",
   "name": "opendss_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
