{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ee70d7-e471-4bba-a190-52312d6821a5",
   "metadata": {},
   "source": [
    "## Create resstock end-use load dataframes at desired aggregation level\n",
    "\n",
    "This notebook does the following:\n",
    "1. Import data (from ResStock Parquet files in SMART-DS)\n",
    "2. Aggregate at resstock building level or aggregated at smart-ds feeder / regional level (aggregates each building type the number of times it appears in phase loads in the feeder/region)\n",
    "3. Add cooling sum\n",
    "4. Save as dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fac54-1aa2-4ff9-9d93-e197cc887ea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd4c2f3-c8c4-4b62-a794-34301e021636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import joblib\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pprint\n",
    "\n",
    "from src import figure_ops\n",
    "from src import input_ops\n",
    "from src import model_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc8f26-a41f-4047-972d-aaf236f989fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ef4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name = 'config1'; config_path = f\"config/{config_file_name}.yaml\"; config = input_ops.load_config(config_path)\n",
    "pprint.pprint(config, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c212e-cc78-4153-9006-e926165963f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import, process and save input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105c1914-9977-4e8c-8218-e2727a64dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, process and save load and weather data (run only once per dataset, e.g., run again if want to add new regions or years)\n",
    "start_time = time.time()\n",
    "\n",
    "# # Define dictionary to store results\n",
    "smartds_load_dict = {}\n",
    "smart_ds_year = config['smart_ds_years'][0]\n",
    "\n",
    "smart_ds_load_path = config['smart_ds_load_path'] + f\"/{smart_ds_year}\"\n",
    "CITY_REGIONS_TO_RUN = config['CITY_REGIONS_TO_RUN']\n",
    "aggregation_level = config['aggregation_level']\n",
    "building_types = config['building_types']\n",
    "start_month = config['start_month']\n",
    "end_month = config['end_month']\n",
    "\n",
    "columns_to_sum = ['cooling_kw', 'fans_kw', 'refrigeration_kw']\n",
    "\n",
    "# Loop through all city, region, year, and building type combinations\n",
    "for city, regions in CITY_REGIONS_TO_RUN.items():\n",
    "    for region in regions:\n",
    "        ### Import and process smart-ds load data ###\n",
    "        parquet_data_path = f'main_folder/SMART-DS/v1.0/{smart_ds_year}/{city}/{region}/load_data' # path to parquet files\n",
    "        region_directory = f\"main_folder/SMART-DS/v1.0/{smart_ds_year}/{city}/{region}/scenarios/base_timeseries/opendss/\" # path to where feeder folders are\n",
    "        # Create a list of load_models (regional / feeders / buildings)   \n",
    "        match aggregation_level:\n",
    "            case 'regional':\n",
    "                load_models = ['regional']\n",
    "            case 'feeder':\n",
    "                # load_models = find_feeder_folders(region_directory) # list of feeders in the format of '/substation/feeder/'\n",
    "                load_models = input_ops.make_feeder_list(region_directory) # list of feeders\n",
    "                print(f'...Loaded feeders in {smart_ds_year} {city} {region}: {load_models}')\n",
    "            case _: # building\n",
    "                load_models = sorted([f for f in os.listdir(parquet_data_path) if f.endswith(\".parquet\")]) # list of buildings in the format of 'building_name.parquet' \n",
    "                # print(f'...Loaded buildings in {smart_ds_year} {city} {region}: {load_models}')\n",
    "        print(f'......Creating data frame for {smart_ds_year} {city} {region} ......')\n",
    "        for load_model in load_models:\n",
    "            for building_type in building_types:\n",
    "                if aggregation_level == 'regional' or aggregation_level == 'feeder':\n",
    "                    print(f'......Creating data frame for {smart_ds_year} {city} {region} {load_model} {building_type}......')\n",
    "                    feeder_path_name = input_ops.add_feeder_upper_folder(load_model)\n",
    "                    feeder_path = f'main_folder/SMART-DS/v1.0/{smart_ds_year}/{city}/{region}/scenarios/base_timeseries/opendss/{feeder_path_name}/Loads.dss'\n",
    "                    load_df = input_ops.aggregate_parquet_data(parquet_data_path, feeder_path, building_type, aggregation_level, start_month, end_month)  # 'res' for residential | 'com' for commercial\n",
    "                    if load_df.empty:\n",
    "                        print(f\"Skipped {feeder_path} since it didn't have parquet files found in the given folder with the specified prefix.\")\n",
    "                        continue \n",
    "                else:\n",
    "                    load_prefix = load_model.split('_')[0]\n",
    "                    if load_prefix not in {'com', 'res'}:\n",
    "                        continue\n",
    "                    load_df = input_ops.get_parquet_load_data(parquet_data_path, load_model,start_month,end_month)\n",
    "                \n",
    "                # Set index to date_time and remove month which gets strage values (temporary solution) \n",
    "                load_df = load_df.reset_index()\n",
    "                load_df.index = load_df[\"date_time\"] # Make date_time the index\n",
    "                input_df = load_df \n",
    "                input_df = input_df.drop('month', axis=1)\n",
    "                \n",
    "                # Add Cooling sum\n",
    "                # Ensure all columns exist in the dataframe before summing\n",
    "                if all(col in input_df.columns for col in columns_to_sum):\n",
    "                    # Check if 'cooling_kw_sum' already exists\n",
    "                    if 'cooling_kw_sum' not in input_df.columns:\n",
    "                        input_df['cooling_kw_sum'] = input_df[columns_to_sum].sum(axis=1)\n",
    "                \n",
    "                # Store in dictionary with (year, city, region, load_model, building_type) as the key\n",
    "                smartds_load_dict[(smart_ds_year, city, region, load_model, building_type)] = input_df\n",
    "        # Save dictionary of current region as joblib files\n",
    "        if aggregation_level == 'building':\n",
    "            input_data_region_dir = f'{smart_ds_load_path}/{city}/{region}/'\n",
    "            if not os.path.exists(input_data_region_dir):\n",
    "                os.makedirs(input_data_region_dir, exist_ok=True)\n",
    "            print(f'saving joblib for {city} {region}')\n",
    "            joblib.dump(smartds_load_dict, os.path.join(input_data_region_dir, f\"smartds_load_dict.joblib\"))                  \n",
    "                     \n",
    "# Save dictionary of all regions as joblib files\n",
    "if aggregation_level == 'regional' or aggregation_level == 'feeder':\n",
    "    print('saving joblib for all regions')\n",
    "    input_data_region_dir = f'{smart_ds_load_path}/all_regions/'\n",
    "    os.makedirs(input_data_region_dir, exist_ok=True)     # Ensure the directory exists\n",
    "    joblib.dump(smartds_load_dict, os.path.join(input_data_region_dir, \"smartds_load_dict.joblib\")) # Save the file\n",
    "\n",
    "end_time = time.time(); print(f\"Runtime for loading data: {(end_time - start_time) / 60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendss_env2",
   "language": "python",
   "name": "opendss_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
