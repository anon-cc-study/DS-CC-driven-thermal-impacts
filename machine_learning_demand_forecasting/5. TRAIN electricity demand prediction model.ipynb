{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train regression models for demand forecasting\n",
    "\n",
    "This script trains regression models using \n",
    "- **Weather data** (historical)\n",
    "- **Demand data** (historical)\n",
    "\n",
    "to predict demand based on:\n",
    "- **Weather data** (historical / future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import joblib\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import yaml\n",
    "import pprint\n",
    "import pwlf\n",
    "\n",
    "from src import input_ops\n",
    "from src import model_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load config file with scenarios and parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name = 'config1'; config_path = f\"config/{config_file_name}.yaml\"; config = input_ops.load_config(config_path)\n",
    "\n",
    "aggregation_level = config['aggregation_level']\n",
    "smart_ds_year = config['smart_ds_years'][0]\n",
    "building_types = config[\"building_types\"]\n",
    "input_data_dict_name = config['input_data_dict_name']\n",
    "Y_column = config['Y_column']\n",
    "X_columns = config['X_columns']\n",
    "\n",
    "## Initialize parameters for saving paths\n",
    "output_path_str = config['output_data_training_path']\n",
    "aggregation_level = config['aggregation_level']\n",
    "\n",
    "if Y_column == 'cooling_kw_sum':\n",
    "    prediction_model_str = config['prediction_model_cooling']\n",
    "elif Y_column == 'heating_kw':\n",
    "    prediction_model_str = config['prediction_model_heating']\n",
    "else:\n",
    "    raise ValueError('Model architecture is not defined for model output! (only for cooling_sum and heating)')\n",
    "    \n",
    "print(f\"Aggregation level: {config['aggregation_level']} \\n SMART-DS year: {config['smart_ds_years'][0]} \\n Months: {config['start_month']}-{config['end_month']} \\n output: {config['Y_column']}, \\n inputs: {config['X_columns_set']} \\n Prediction model: {prediction_model_str} \\n output directory:{config['output_data_training_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load input data (Resstock weather data & smart-ds load data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load input load & weather data of year-city-region-building_type combinations\n",
    "loaded_input_data_dict = {}\n",
    "if config['aggregation_level'] == 'building': # Assuming buildings have separate joblib files\n",
    "    for city, region in CITY_REGIONS_TO_RUN.items():\n",
    "        path_temp = os.path.join(config[\"input_data_training_path\"], f\"{city}/{region}/{input_data_dict_name}.joblib\")\n",
    "        print(path_temp)\n",
    "else:\n",
    "    print(f'Loading dictionary with load & weather data from {config[\"input_data_training_path\"]}')\n",
    "    loaded_input_data_dict = joblib.load(os.path.join(config[\"input_data_training_path\"], f\"{input_data_dict_name}.joblib\")) # Load dictionary with load & weather data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train ML models and save models, scalers and metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train MLP model for year-city-region-building_type combinations\n",
    "start_time = time.time()\n",
    "\n",
    "## Initialize dictionaries\n",
    "mlp_results = {} # change to mlp_metrics_dict\n",
    "mlp_model_dict = {}\n",
    "xnorm_dict = {}\n",
    "ynorm_dict = {}\n",
    "\n",
    "for smart_ds_year, city, region, load_model, building_type in loaded_input_data_dict.keys():\n",
    "    print(f\".......Training {prediction_model_str} for {smart_ds_year} {city} {region} {load_model} {building_type}.......\")\n",
    "    # Train MLP model\n",
    "    # Load data\n",
    "    if not config['aggregation_level'] == 'building':\n",
    "        input_df = loaded_input_data_dict[(smart_ds_year, city, region, load_model, building_type)]\n",
    "    else:\n",
    "        print(\"To train model at the building level: (1) create processed input data at the building level, and (2) update code here to load it\")\n",
    "\n",
    "    match prediction_model_str:\n",
    "        case 'MLP_2_1452_10':\n",
    "            first_L_n = 1452\n",
    "            second_L_n = 10\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'MLP_2_4096_512': \n",
    "            first_L_n = 2048\n",
    "            second_L_n = 256\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n) \n",
    "        case 'MLP_2_2048_512': \n",
    "            first_L_n = 4096\n",
    "            second_L_n = 512\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)    \n",
    "        case 'MLP_2_1024_128': \n",
    "            first_L_n = 1024\n",
    "            second_L_n = 128\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'MLP_2_512_64': \n",
    "            first_L_n = 512\n",
    "            second_L_n = 64\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'MLP_2_256_32':\n",
    "            first_L_n = 256\n",
    "            second_L_n = 32\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'MLP_2_100_10':\n",
    "            first_L_n = 100\n",
    "            second_L_n = 10\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'MLP_2_32_16':\n",
    "            first_L_n = 32\n",
    "            second_L_n = 16\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'MLP_1_16':\n",
    "            first_L_n = 16\n",
    "            second_L_n = ''\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, y_train, y_train_pred, training_runtime = model_ops.train_mlp_model(input_df, X_columns, Y_column, first_L_n, second_L_n)\n",
    "        case 'PWLR_4bp':\n",
    "            # X_columns = ['Dry Bulb Temperature [Â°C]']\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, training_runtime = model_ops.train_piecewise_linear_model(input_df, X_columns, Y_column, num_breakpoints=4)\n",
    "        case 'Poly_4deg':\n",
    "            MLP_model, poly_transform, xnorm, ynorm, y_test, y_test_pred, training_runtime = model_ops.train_polynomial_model(input_df, X_columns, Y_column, degree=4, alpha=1.0)\n",
    "        case _:\n",
    "            MLP_model, xnorm, ynorm, y_test, y_test_pred, training_runtime = model_ops.train_linear_model(input_df, X_columns, Y_column)\n",
    "\n",
    "    # compute MLP performance metrics\n",
    "    r2, mae, mape, rmse, nrmse, peak_load_error, peak_time_error, mape_high, nrmse_high = model_ops.metrics_test_data(y_test, y_test_pred)\n",
    "\n",
    "    # Save MLP performance metrics\n",
    "    mlp_results[(smart_ds_year, city, region, load_model, building_type)] = {\n",
    "        \"X_columns\": X_columns,\n",
    "        \"Y_column\": Y_column,\n",
    "        \"training_runtime\": training_runtime,\n",
    "        \"y_test\": y_test, \n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"y_train\": y_train, \n",
    "        \"y_train_pred\": y_train_pred,\n",
    "        \"r2\": r2,\n",
    "        \"mae\": mae,\n",
    "        \"mape\": mape,\n",
    "        \"rmse\": rmse,\n",
    "        \"nrmse\": nrmse,\n",
    "        \"peak_load_error\": peak_load_error,\n",
    "        \"peak_time_error\": peak_time_error,\n",
    "        \"mape_high\": mape_high,\n",
    "        \"nrmse_high\": nrmse_high\n",
    "    }\n",
    "    \n",
    "    # Save trained models and scalers in dictionaries\n",
    "    mlp_model_dict[(smart_ds_year, city, region, load_model, building_type)] = MLP_model\n",
    "    xnorm_dict[(smart_ds_year, city, region, load_model, building_type)] = xnorm\n",
    "    ynorm_dict[(smart_ds_year, city, region, load_model, building_type)] = ynorm\n",
    "\n",
    "# Save dictionaries as joblib files\n",
    "joblib.dump(mlp_results, os.path.join(output_path_str, \"metrics\", f\"{prediction_model_str}_results.joblib\"))\n",
    "joblib.dump(mlp_model_dict, os.path.join(output_path_str, \"models\", f\"{prediction_model_str}_models_dict.joblib\"))\n",
    "joblib.dump(xnorm_dict, os.path.join(output_path_str, \"scalers\", f\"{prediction_model_str}_xnorm_dict.joblib\"))\n",
    "joblib.dump(ynorm_dict, os.path.join(output_path_str, \"scalers\", f\"{prediction_model_str}_ynorm_dict.joblib\"))\n",
    "\n",
    "print(\"All models, scalers, and results saved successfully!\")\n",
    "\n",
    "end_time = time.time(); print(f\"Runtime for Training models: {(end_time - start_time) / 60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendss_env2",
   "language": "python",
   "name": "opendss_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
